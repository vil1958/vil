[https://websetnet.net/ru/how-to-find-where-a-program-is-installed-in-linux-ubuntu/](https://websetnet.net/ru/how-to-find-where-a-program-is-installed-in-linux-ubuntu/)

[Linux training academy](https://www.linuxtrainingacademy.com/)

[## trash-cli - Command Line Interface to FreeDesktop.org Trash.](https://github.com/andreafrancia/trash-cli)


### [Trash-cli, корзина для интерпретатора командной строки](https://ubunlog.com/ru/trash-cli-%D0%BC%D1%83%D1%81%D0%BE%D1%80%D0%BD%D0%B0%D1%8F-%D0%BA%D0%BE%D1%80%D0%B7%D0%B8%D0%BD%D0%B0-%D0%B4%D0%BB%D1%8F-%D0%B8%D0%BD%D1%82%D0%B5%D1%80%D0%BF%D1%80%D0%B5%D1%82%D0%B0%D1%82%D0%BE%D1%80%D0%B0-%D0%BA%D0%BE%D0%BC%D0%B0%D0%BD%D0%B4%D0%BD%D0%BE%D0%B9-%D1%81%D1%82%D1%80%D0%BE%D0%BA%D0%B8/)
Установить trash-cli в Ubuntu очень просто **используя менеджер пакетов apt**. Все, что вам нужно сделать, это открыть терминал (Ctrl + Alt + T) и выполнить команду:
`sudo apt-get install trash-cli`

Инструмент trash-cli основан на Python, поэтому **Мы также можем установить его из исходников**. Процедура общая для всех дистрибутивов. Вам просто нужно открыть терминал (Ctrl + Alt + T) и запустить команды:
`git clone https://github.com/andreafrancia/trash-cli.git`
`cd trash-cli`
`sudo python3 setup.py install`
`sudo python3 setup.py install --user`

Теперь мы можем очень просто использовать эти команды, доступные из терминала. Например, если мы хотим **отправить что-нибудь в корзину вместо использования rm** (_это было бы в принципе безвозвратно_), вы можете использовать другую команду:
`trash-put ejemplo-trash-cli.txt`

**Trash-cli на самом деле не удаляет файлы или каталоги, он просто перемещает их в скрытый каталог. ОСТОРОЖНО, каждый файл или каталог сохранит путь, по которому он был изначально. Это означает, что если вы позже восстановите его, он будет в каталоге, из которого мы его удалили.  
**

Скрытый каталог, в который удалены файлы и каталоги, мы можем увидеть с помощью команды:
`ls -la $HOME/.local/share/Trash`

В этом скрытом каталоге вы найдете еще два каталога:
- _файлов_: **Сюда команда trash-put переместит удаленный файл или каталог.**.
- _info_: **Группа команд обрабатывает файл .trashinfo для каждого удаленного файла / каталога.**.
**перечислить файлы или каталоги, найденные в корзине**, из командной строки выполняем:
`trash-list`

**освободить место для мусора**. И мы можем сделать это с помощью команды:
`trash-empty`
если мы хотим удалить то, что хранилось за последние 5 дней, мы должны написать:
`trash-empty 5`

**Trash-restore восстанавливает файлы или каталоги на их исходное место**, помните, что эта информация хранится в корзине:
`trash-restore`

С помощью команды trash-rm мы можем **навсегда удалить файлы или каталоги из корзины**. У нас есть несколько способов выполнить эту задачу. С первой **мы удалим файл по имени**:
`trash-rm ejemplo-trash-cli.txt`

Мы также можем выбрать **удалить все файлы с определенным расширением**:
`trash-rm '*.txt'`

Если бы мы хотели **удалить папку из корзины**, используйте следующую команду:
`trash-rm carpeta-ejemplo`

Можно найти наиболее полную справку **на странице руководства**:
`man trash`

### How to auto delete files older that 30 days?
Run this:
`(crontab -l ; echo "@daily $(which trash-empty) 30") | crontab -`

This will update your crontab file with a trash-empty command that runs daily and removes files older than 30 days. To review your crontab use:
`crontab -l`

### [How can I empty the trash](https://askubuntu.com/questions/468721/how-can-i-empty-the-trash-using-terminal)

`rm -rf ~/.local/share/Trash/*

After you
`sudo apt install trash-cli`
`sudo apt-get install trash-cli`
you can do
```
trash-empty
```
More interesting details about trash handling below and in [the man page](http://manpages.ubuntu.com/manpages/focal/man1/trash-empty.1.html).
```bash
restore-trash (1)    - Restore for Command line trash utility.
trash (1)            - Command line trash utility.
trash-empty (1)      - Empty for Command line trash utility.
trash-list (1)       - List trashed files.
trash-put (1)        - Command line trash utility.
trash-rm (1)         - Removes files matching a pattern from the trash can
```
Please note, `~/.local/share/Trash/*` might not be the only location that stores the trashed files, so removing that path is not enough if you have other partitions that also have a trash folder.

If you want to empty the trash in all available partitions, you can use the following command to empty the trash:
```
gio trash --empty
```

`gio` is provided by glib2, which is used by most GTK-based applications, and the `gio` binary should be available out-of-the-box in most of the cases if you are using a desktop environment. If not, you can install it via:
```
apt-get install libglib2.0-bin
```

удаляй всю папку Trash и у юзера и у рута, при первой же надобности система создаст заново.  
`sudo nautilus`    
а потом удаляй папки  
`/home/user/.local/share/Trash`  
  и  
`/root/.local/share/Trash`

[### Псевдонимы, создание временных или постоянных псевдонимов для наиболее часто используемых команд](https://ubunlog.com/ru/%D0%BF%D0%BE%D1%81%D1%82%D0%BE%D1%8F%D0%BD%D0%BD%D1%8B%D0%B5-%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5-%D0%BF%D1%81%D0%B5%D0%B2%D0%B4%D0%BE%D0%BD%D0%B8%D0%BC%D1%8B-%D0%BA%D0%BE%D0%BC%D0%B0%D0%BD%D0%B4%D1%8B/)
Пользователи GNU / Linux часто нуждаются в **используйте одну и ту же команду снова и снова**. Многократный ввод или копирование одной и той же команды может снизить производительность и отвлечь вас от того, что вы на самом деле делаете.

Мы можем сэкономить время **создание псевдонимов для наиболее часто используемых команд**. Это что-то вроде пользовательских ярлыков. Используется для представления команды (или набора команд), выполняемой с настраиваемыми параметрами или без них.

Некоторые не рекомендуют использовать подобные инструменты, поскольку, несмотря на их большую полезность, **его использование может быть контрпродуктивным**. Специально для пользователей, которые только начинают знакомиться с миром Gnu / Linux и его терминалом. Поскольку, хотя использование пользовательских команд может быть очень полезным и дружелюбным, это также может заставить нас забыть о настоящих командах.

## Список псевдонимов на вашем Ubuntu

Этот инструмент уже установлен по умолчанию в нашей Ubuntu. Чтобы использовать его, нам нужно только отредактировать **[.bashrc файл](https://ubunlog.com/ru/bashrc-%D0%B8%D0%B7%D0%BC%D0%B5%D0%BD%D1%8F%D0%B5%D1%82-%D0%BF%D1%80%D0%B8%D0%B3%D0%BB%D0%B0%D1%88%D0%B5%D0%BD%D0%B8%D0%B5-bash/ "Bashsr, измените промт bash") что скрыто в личной папке**.

Прежде всего, мы сможем увидеть **список, определенный в нашем профиле** просто запустив эту команду в терминале (Ctrl + Alt + T):
`alias`

```
alias
alias ls='ls --color'
alias usage='du -sk * | sort -n | perl -ne '\''($s,$f)=split(m{\t});for (qw(K M G)) {if($s<1024) {printf("%.1f",$s);print "$_\t$f"; last};$s=$s/1024}'\'''
```
## Как создавать псевдонимы
Их создание - относительно быстрый и простой процесс. Кто угодно может создать **некоторые из этих двух типов: временные и постоянные**.

### Создать временные псевдонимы
Что нам нужно сделать, так это написать слово псевдоним в терминале. Затем нам нужно будет использовать имя, которое мы хотим использовать для выполнения команды. За этим последует знак '=' и вызов команды, которую мы хотим использовать.
Синтаксис следующий:
`alias htdocs="cd /opt/lampp/htdocs"`

После определения мы сможем использовать ярлык htdocs для перехода в каталог htdocs. Проблема с этим ярлыком в том, что **будет доступен только для текущего сеанса терминала**. Если вы откроете новый сеанс терминала, псевдоним больше не будет доступен. Если вы хотите сохранять их между сеансами, вам понадобится постоянный.
### Создать постоянные псевдонимы
Чтобы псевдонимы между сеансами сохранялись, вам нужно будет сохранить их в папке **файл профиля для конфигурации оболочки вашего пользователя**. Это могут быть:

- Баш → _~ / .bashrc_
- ЗШ → _~ / .Zshrc_
- Рыба → _~ / .config / fish / config.fish_

Синтаксис в этом случае такой же, как и при создании временного. Единственная разница заключается в том, что на этот раз мы сохраним его в файл. Так, например, в bash вы можете открыть файл .bashrc в своем любимом редакторе:
`vim ~/.bashrc`

Внутри файла найдите место для сохранения псевдонимов. Их лучше всего добавить в конец файла. В организационных целях вы можете оставить комментарий перед:
`#Mis alias personalizados`
`alias imagenes="cd /home/sapoclay/Imágenes/"`
`alias actualizarsistema="sudo apt update && sudo apt upgrade"`
`alias pingxbmc="ping 192.168.1.100"`

Когда закончите, сохраните файл. **Этот файл будет автоматически загружен в следующий сеанс.**. Если вы хотите использовать то, что только что написали в текущем сеансе, выполните следующую команду:
`source ~/.bashrc`

Мы также сможем **иметь наши псевдонимы в отдельном документе**. Чтобы определить постоянный псевдоним, вам просто нужно следовать инструкциям, которые показывает нам файл bashrc. Мы сможем иметь **отдельный файл с именем `.bash_aliases` для их хранения**.

Чтобы применить изменения немедленно, мы можем использовать следующую команду:
source ~/.bash_aliases

**удалить псевдоним, добавленный через командную строку**, вы можете использовать команду unalias.
`unalias nombre_del_alias`
В случае желания **удалить все определения псевдонимов**, мы можем выполнить следующую команду:
`unalias -a [elimina todos los alias]`

Имейте в виду, что **команда unalias также применяется только к текущему сеансу**. Чтобы удалить его навсегда, мы должны удалить соответствующую запись в файле ~ / .bash_aliases.

Еще нужно иметь в виду, что если у нас есть постоянный псевдоним и мы добавляем временный во время сеанса с тем же именем, **временный будет иметь более высокие привилегии во время текущего сеанса**.

Это был небольшой пример руководства по созданию собственных псевдонимов для выполнения часто используемых команд. За **узнать больше об этом инструменте**, вы можете ознакомиться со статьей, написанной в [Википедия](https://es.wikipedia.org/wiki/Alias_(Unix) "Определение псевдонимов - Википедия").

### Где была установлена ​​программа (включая все вспомогательные файлы, так что это может быть длинный список, который вам нужно будет искать)

### Синтаксис команды

### `dpkg-query -L APPLICATION-NAME`

### Применение

### `dpkg-query -L firefox`

dpkg-query -L czkawka_gui

thunar

file manager for xfce desktop

Thunar это быстрый и простой в использовании файловый

менеджер для рабочего окружения Xfce. [https://docs.xfce.org/xfce/thunar/start](https://docs.xfce.org/xfce/thunar/start)

запускать с админ правами

pkexec /usr/bin/bleachbit

pkexec appears not to do this by design. I had a really specific use case where I wanted pkexec to be able to execute things in the working directory. The answer I came up with was to write two scripts: script A changes directory to the first argument and then executes the other arguments as a command, and script B calls pkexec on script A, with the current directory as the first argument and the rest of the arguments as the "real" arguments.

не забывая сделать файл исполняемым.

`chmod ugo+x файл_скрипта`

Script A ("exec-in-dir" -- must be installed in /usr/local/bin or somewhere universal):

#!/bin/bash

cd $1

shift

eval $@

Script B ("pkw"):

#!/bin/bash

pkexec exec-in-dir $PWD "$@"

pkexec --user myuser pwd

that will execute pwd in the user home folder (/home/myuser) instead of the previous path (/home/myuser/Desktop)

xterm -e sudo ls

====================

скрипт для запуска программы с root правами

/usr/local/bin/startprg.sh

#!/bin/bash

if [ -z $1 ]; then

 echo -e "at least 1 argument required!\n" >> /dev/stderr

 exit 1

fi

COMMAND=$1

shift #shift first arg

for ARG in "$@"

do

 if [ -z "$ARGS" ]; then

  ARGS="$ARG"

 else

  ARGS="$ARGS $ARG"

 fi

done

ARGS=\'$ARGS\'

eval pkexec env DISPLAY=$DISPLAY XAUTHORITY=$XAUTHORITY $COMMAND $ARGS

exit 0

в file.desktop `Exec=/путь/до/скрипта /путь/до/программы`

Exec=/usr/local/bin/startprg.sh /usr/bin/doublecmd %F

Работает, только при запуске пароль требует. Как просто кликом запускать?

`xterm -e sudo bash`

Exec=xterm -e sudo ls

в файле

/etc/sudoers

можно прописать:

Вместо XXX - ваш пользователь в системе (root или vil)

XXX ALL=(ALL) NOPASSWD:ALL

Можно не так радикально, а только для одной программы:

`XXX ALL=NOPASSWD: /put/k/programme`

`XXX ALL=(ALL) NOPASSWD:/usr/bin/doublecmd`

Теперь в ярлыке достаточно прописать:

`Exec=sudo doublecmd`

se the GVfs admin backend, just add `admin://` to the beginning of the full path to your preferred directory.

Open Nautilus the usual way and press Ctrl+L to enable typing in the address-bar, and then enter for example `admin:///usr/` to open the `/usr/` directory.

Enter your admin password when prompted

admin:///usr/

# HOW-TO: Привязка файлов

[https://help.ubuntu.ru/fullcircle/27/files](https://help.ubuntu.ru/fullcircle/27/files)

[https://russianpenguin.ru/2016/01/04/linux-%D1%81%D0%B2%D1%8F%D0%B7%D1%8B%D0%B2%D0%B0%D0%B5%D0%BC-%D0%BF%D1%80%D0%B8%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5-%D1%81-%D1%82%D0%B8%D0%BF%D0%B0%D0%BC%D0%B8-%D1%84%D0%B0%D0%B9%D0%BB%D0%BE/](https://russianpenguin.ru/2016/01/04/linux-%D1%81%D0%B2%D1%8F%D0%B7%D1%8B%D0%B2%D0%B0%D0%B5%D0%BC-%D0%BF%D1%80%D0%B8%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5-%D1%81-%D1%82%D0%B8%D0%BF%D0%B0%D0%BC%D0%B8-%D1%84%D0%B0%D0%B9%D0%BB%D0%BE/)

### Соксификатор dante

[https://habr.com/ru/post/133703/](https://habr.com/ru/post/133703/)

### apt-get install dante-client

### # пример для Debian-based систем

### Использование:

`# Если требуется зайти по ssh на сервер`

`SOCKS_PASSWORD=``""` `SOCKS_SERVER=``"11.22.33.44:1080"` `socksify ssh myserver`

`# Тоже самое, только если для подключения к соксу требуется авторизация`

`SOCKS_USERNAME=``"user"` `SOCKS_PASSWORD=``"password"` `SOCKS_SERVER=``"11.22.33.44:1080"` `socksify ssh myserver`

`# Пример с использованием IRC клиента - irssi`

`SOCKS_PASSWORD=``""` `SOCKS_SERVER=``"11.22.33.44:1080"` `socksify irssi`

`# Тоже самое, только с использованием HTTP proxy с поддержкой метода CONNECT`

`HTTP_CONNECT_PROXY=``"http://11.22.33.44:8080"` `socksify irssi`

### С помощью socksify можно направить через proxy почти любое приложение, не только консольное.

### Чтобы все время не вводить данные о proxy можно создать файл 

_/etc/socks.conf_

### Пример для SOCKS:

### route { from: 0.0.0.0/0 to: 0.0.0.0/0 via: socks.zaboronahelp.pp.ua port = 1488 protocol: tcp udp proxyprotocol: socks_v4 socks_v5 method: none }

### Пример для HTTP proxy с авторизацией:

`route {`

`from: 0.0.0.0/0 to: 0.0.0.0/0 via: 11.22.33.44 port = 8080`

`command: connect`

`proxyprotocol: http`

`method: username`

`}`

### А также экспортировать переменные SOCKS_USERNAME и SOCKS_PASSWORD, если для SOCKS или HTTP proxy требуется авторизация:

export SOCKS_USERNAME="username"

export SOCKS_PASSWORD="password"

### DNS запросы через proxy

### Часто требуется чтобы и преобразование имен происходило через proxy. Если использовать dante, то запрос на преобразование имен идет и через proxy, и через именной сервер указанный в 

_/etc/resolv.conf_ 

### . Понять почему же идет два одинаковых запроса вместо одного не удалось. Поэтому можно предложить два варианта:

### 1) Закомментировать именные сервера в файле 

_/etc/resolv.conf_

### , чтобы преобразование имен шло только через proxy. Это отразится на всей системе.

### 2) Изменить 

_/etc/resolv.conf_

###  и выставить именные сервера необходимой страны, или просто отличные от серверов провайдера. Например установить сервера Google:

`nameserver 8.8.8.8`

`nameserver 8.8.4.4`

### Чтобы данные не были перезаписаны именными серверами провайдера (при переподключении), можно запретить обновление списка именных серверов сетевому менеджеру (NetworkManager/wicd) или DHCP-клиенту (спасибо 

[ergil](http://habrahabr.ru/users/ergil/)

###  за корректировку).

### Или воспользоваться «грубым» методом — запрещением изменения файла 

_/etc/resolv.conf_

### :

`sudo chattr +i /etc/resolv.conf`

D:\Users\vil\AppData\Local\Vivaldi\Application\vivaldi.exe --flag-switches-begin --proxy-server=socks5://localhost:12345 --flag-switches-end

vivaldi.exe --proxy-server="socks5://127.0.0.1:12345"

D:\Users\vil\AppData\Local\Vivaldi\Application\vivaldi.exe --proxy-server="socks5://127.0.0.1:12345"

D:\Users\vil\AppData\Local\Vivaldi\Application\vivaldi.exe --proxy-server=socks5://socks.zaboronahelp.pp.ua:1488

vivaldi --proxy-server=socks5://socks.zaboronahelp.pp.ua:1488

# СОЗДАНИЕ И НАСТРОЙКА SOCKS5 ПРОКСИ СЕРВЕРА В UBUNTU

[https://la2ha.ru/dev-seo-diy/unix/socks5-proxy-server-ubuntu](https://la2ha.ru/dev-seo-diy/unix/socks5-proxy-server-ubuntu)

# Как проверить, какую среду рабочего стола вы используете в Linux

[https://linuxcool.net/instrukczii/kak-proverit-kakuyu-sredu-rabochego-stola-vy-ispolzuete-v-linux/](https://linuxcool.net/instrukczii/kak-proverit-kakuyu-sredu-rabochego-stola-vy-ispolzuete-v-linux/)

echo $XDG_CURRENT_DESKTOP

### Вы также можете просмотреть двоичный файл *-session, который обычно находится в каталоге /usr/bin, чтобы получить аналогичные результаты.

ls /usr/bin/*-session

### Neofetch – это инструмент командной строки, который отображает информацию о системе в презентабельном формате. Neofetch не входит в стандартные пакеты Linux, поэтому вам придется вручную установить его на вашу систему.

sudo apt install neofetch

neofetch

### Как узнать название дистрибутива Linux и его версию выпуска

[https://linuxcool.net/other/kak-uznat-kakuyu-versiyu-linux-vy-ispolzuete/](https://linuxcool.net/other/kak-uznat-kakuyu-versiyu-linux-vy-ispolzuete/)

cat /etc/os-release

cat /etc/issue

lsb_release -a

### Как узнать версию ядра Linux

uname -a

cat /proc/version

[https://t.me/srv_admin/1770](https://t.me/srv_admin/1770)

Ранее я рассматривал софт для восстановления удалённых файлов в Linux. В комментариях возникали вопросы и обсуждения по поводу механики этого процесса. Сегодня рассмотрим немного теории и частный практический пример из этой области.

Файлы в Linux удаляются с помощью системного вызова unlink. Он удаляет имя из файловой системы. Если это имя было последней ссылкой на файл и больше нет процессов, которые держат этот файл открытым, данный файл удаляется и место, которое он занимает, освобождается для дальнейшего использования. Если имя было последней ссылкой на файл, но какие-либо процессы всё ещё держат этот файл открытым, файл будет оставлен, пока последний файловый дескриптор, указывающий на него, не будет закрыт.

Исходя из этой информации можно легко восстанавливать удалённые файлы, удерживаемые процессом. Выполним простой эксперимент с помощью bash. Создадим тестовый скрипт именем script.sh следующего содержания:

#!/bin/bash

sleep 30000

exit

Устанавливаем бит исполняемости:

# chmod u+x ./script.sh

Запускаем скрипт в фоне и удаляем.

# ./script.sh &

# rm -f ./script.sh

Итак, у нас есть процесс оболочки, который удерживает файл скрипта. Имени уже нету, но есть дескриптор, с которым ассоциирован файл. Нужно получить дескриптор файла. В этом нам поможет команда lsof:

# lsof -c script.sh

В выводе нас интересует PID - идентификатор процесса и FD - дескриптор, ассоциированный со скриптом:

script.sh 17871 root 255r REG 8,1 30 8400545 /tmp/script.sh (deleted)

Читаем содержимое файла скрипта.

# cat /proc/17871/fd/255

Перенаправляем вывод cat в файл:

# cat /proc/17871/fd/255 > new_script.sh

Получаем наш исходный скрипт, который удалили.

Поднимаем процесс из фона и уничтожаем.

# fg

CTRL+C

Теоретически таким образом можно восстановить удалённые файлы виртуальных машин. Я не раз получал вопросы по этому поводу. Некоторые умудряются по ошибке удалить исходный файл VM, а потом через 2 недели заметить это. При этом машина всё это время успешно работает.

Сохраните заметку в закладки, может пригодиться в самом неожиданном случае. У меня бывало, что по ошибке удалял конфиг работающей программы. Казалось бы, вот он только что был, ты его грохнул, а как вернуть, не понимаешь.

#terminal #restore

VPN Server #vpn #wireguard [https://t.me/srv_admin/1775](https://t.me/srv_admin/1775)

ктуальность VPN растёт день ото дня. Сейчас столько всяких событий происходит с защитами, запретами, ограничениями и т.д., что голова кругом идёт. Доходит до того, что мой сайт serveradmin.ru, который хостится в Москве, у кого-то в России открывается только через VPN. Я даже не знаю, как расследовать такие инциденты. Явно есть проблемы у каких-то операторов.

Существует очень удобная и простая в плане установки и настройки панель для управления VPN на базе популярного и современного WireGuard под названием Firezone. Это бесплатный Open Source продукт. С её помощью можно управлять всеми настройками WireGuard через браузер.

Для Firezone подготовлен установщик, который автоматом всё развернёт на вашем сервере, в том числе и WireGuard. Достаточно только запустить готовый bash скрипт. Сейчас разумно предостеречься от подобных методов, так что можно установить всё вручную. Это описано в документации ([https://docs.firez.one/docs/deploy/server/](https://docs.firez.one/docs/deploy/server/)). Сам Firezone собран в rpm или deb пакет. Компоненты web-интерфейса выполняются под непривилегированным пользователем. Поддерживаются все современные Linux дистрибутивы.

Из дополнительных плюшек, помимо управления пользователями, Firezone умеет управлять nftables для ограничения доступа клиентов к каким-то хостам. Все настройки выполняются через веб интерфейс, который построен на базе Admin One Bulma Dashboard ([https://github.com/firezone/admin-one-bulma-dashboard](https://github.com/firezone/admin-one-bulma-dashboard)).

Проект претендует на нечто большее, чем уровень pet project и пилит коммерческую версию с разными способами аутентификации, а так же интеграцией с SAML и LDAP. Из всех панелей управления WireGuard эта показалась наиболее приятной и проработанной. Остальные можете посмотреть по метке в конце поста.

Сайт - [https://www.firez.one/](https://www.firez.one/)

Исходники - [https://github.com/firezone/firezone](https://github.com/firezone/firezone)

Документация - [https://docs.firez.one/](https://docs.firez.one/)

Demo - [https://demo.firez.one/](https://demo.firez.one/)

#vpn #wireguard

--------------------------------------------------------------------------------------------

### truncate

[https://t.me/srv_admin/1791](https://t.me/srv_admin/1791)

Во вчерашней заметке вскользь упомянул про утилиту truncate. Решил рассказать про неё поподробнее, так как сам иногда использую. С её помощью можно усечь текстовый файл, либо полностью обнулить, не удаляя его. Это удобно, когда нужно очистить лог файл, но не хочется его удалять, создавать заново, выставлять права доступа и перезапускать сервис, который его использовал.

Утилита truncate чаще всего входит в базовый состав системных утилит, которые идут в комплекте с дистрибутивом Linux. Если её нет, то можно установить пакет coreutils, она скорее всего будет там.

Вообще, самый простой способ обнулить файл, это сделать вот так:

# > access.log

Это в оболочке bash. В каких-то других может не сработать и нужно будет какую-то команду типа echo -n или cat /dev/null добавить перед перенаправлением. С truncate очистка файла выглядит так:

# truncate -s 0 access.log

Truncate позволяет не только полностью обнулить файл, но и сохранить какую-то его часть, что актуально для логов. Если у вас образовался огромный лог файл от веб сервера, который вам точно не нужен, но вы хотите что-то поискать в его начале, то просто обрежьте его до нужного размера:

# truncate -s 10M access.log

Конец будет отсечён до нового размера файла в 10 мегабайт. Обращаю внимание, что обрезается хвост файла, а не начало. Это принципиальный момент, так как truncate не читает файл, а просто отсекает лишнее, поэтому работает очень быстро на любых объемах. Мне как-то нужно было удалить именно начало большого файла, оставив конец. С удивлением обнаружил, что это не так просто сделать. Так и не придумал простого и удобного решения. Использовал tail -n и перенаправление в новый файл.

Другой возможностью truncate является создание файлов заданного размера. На практике лично мне это никогда не было нужно и я не знаю, где может пригодиться. Только если в каких-то тестах. Тем не менее с truncate это сделать проще всего. Создаём файл:

# truncate -s 10M file.txt

Получили файл в 10 мегабайт, заполненный нулями.

Также с truncate удобно увеличивать размер файла порциями. Есть какой-то файл, его надо увеличить на 10 мегабайт:

# truncate -s +10M file.txt

Если использовать вместо плюса минус, файл будет уменьшен на 10 мегабайт. Это может быть полезно, когда тестируется какой-то триггер в мониторинге на контроль размера файла. Например, если дамп sql базы слишком маленький, нужно обратить на это внимание.

#terminal #bash

=========================================================

## FIND

[https://t.me/srv_admin/1793](https://t.me/srv_admin/1793)

В закладочках нашёл любопытный сервис, который очень полезен линуксоидам - конструктор для консольной команды FIND. Это такая типичная линуксовая утилита, у которой 100500 параметров и возможностей, ключи которой невозможно запомнить раз и навсегда. У меня огромная шпаргалка по find на все случаи жизни, чтобы не приходилось заново вспоминать, как реализовать тот или иной поиск.

Кое-что необычное по find уже публиковал на канале:

- очистка старых файлов ([https://t.me/srv_admin/1735](https://t.me/srv_admin/1735))

- поиск дубликатов файлов ([https://t.me/srv_admin/1368](https://t.me/srv_admin/1368))

- утилита fd для упрощения поиска через find ([https://t.me/srv_admin/1254](https://t.me/srv_admin/1254))

Сервис называется find-command-generator ([https://ittricks.ru/utilities/find-command-generator](https://ittricks.ru/utilities/find-command-generator)). С его помощью узнал, что find очень просто может находить файлы, которые принадлежат несуществующему пользователю или группе, или обоим одновременно. Бывает нужно такие найти:

# find . -nogroup -nouser

Сервис пригодится, когда нужно найти что-то с параметрами, типа ограничения по датам изменения или доступа, размеру, правам доступа и т.д. Типичная история, когда надо проверить директорию веб сервера и снять с файлов все права на исполнение:

# find /web/site/www -type f -name "*" -perm u+x -exec chmod 664 {} \;

Программисты любят ставить 777 без разбора. Постоянно с этим сталкиваюсь. Когда у них что-то работает не так, они первым делом права доступа 777 ставят, а потом дальше разбираются.

#bash #terminal

============================================================

## SPLIT

[https://t.me/srv_admin/1795](https://t.me/srv_admin/1795)

Продолжаю ваc знакомить с утилитами командной стоки Linux, которыми пользуюсь сам. На днях вспомнил про SPLIT. С её помощью можно делить файлы на части. Чаще всего это нужно для больших архивов, которые требуется разбиться на части перед передачей по интернету. Так проще передать большой файл.

Я не помню, чтобы мне приходилось когда-нибудь ставить split отдельно. Обычно она есть в стандартном системном наборе во всех дистрибутивах, с которыми приходится работать.

Конкретно я split использую, когда нужно отправить в S3 хранилище какой-то большой архив. Во многих инструкциях по S3 указывается, что большие файлы отправлять не рекомендуется. Под большими подразумевается что-то больше 2-3 Гигабайт. Так что такие файлы приходится разбивать.

В общем случае разбить файл с помощью split можно следующим образом:

# split -b 100M file

На выходе получим некоторый набор файлов в зависимости от размера исходного. Имена у файлов будут вида xaa, xab, xaс и т.д., что явно неудобно. Поэтому на практике лучше сразу указать маску, по которой будут создаваться новые файлы:

# split -b 2M file file_ -a 2 -d

Мы указали длину префикса 2 и использование чисел. На выходе будут файлы file_00, file_01, file_02 и т.д., что мне видится удобнее дефолтных масок.

Собрать файлы обратно можно следующим образом:

# cat file_* > file

Если вы просто хотите разделить файл на 5 частей вне зависимости от того, какого они будут размера, то делается это следующим образом:

# split -n 5 file file_ -a 2 -d

Вот пример использования split на бэкапе большого сайта для дальнейшей передачи его в S3. Пример условный, так как вынул его из большого скрипта и все переменные указал явно. То есть это не мой окончательный рабочий вариант, а адаптированный пример:

# Делаем архив с относительным путём внутри

/usr/bin/tar --exclude='cache/*' \

-czvf /mnt/backup/site.ru_`date +"%Y-%m-%d_%H-%M"`.tar.gz \

-C /web/sites/site.ru www

# Разбиваем архив на части

/usr/bin/split -b 2048m \

/mnt/backup/site.ru_`date +"%Y-%m-%d_%H-%M"`.tar.gz \

"/mnt/backup/site.ru_`date +"%Y-%m-%d_%H-%M"`.tar.gz-part-"

# Удаляем исходный файл

/usr/bin/rm -rf /mnt/backup/site.ru_`date +"%Y-%m-%d_%H-%M"`.tar.gz

# Заливаем в S3

/usr/bin/rclone copy /mnt/backup s3storage:week

# Чистим локальный бэкап от старых архивов

/usr/bin/find /mnt/backup -type f -mtime +7 -exec rm {} \;

Отдельно отмечу, что подобные бэкапы обязательно нужно проверять. У меня S3 это не основной бэкап, а холодное хранилище для них. Эти же бэкапы хранятся где-то ещё, разворачиваются и проверяются, так как туда ещё и дамп базы обычно кладётся, чтобы всё в одном месте было.

#terminal #bash

=====================================================

cmod [https://t.me/srv_admin/1813](https://t.me/srv_admin/1813)

На днях в комментариях зашёл разговор о ситуации, когда с утилиты chmod сняли бит исполнения. Эта утилита как раз предназначена для того, чтобы этот бит ставить. Теоретически получается тупиковая ситуация. Это, кстати, отличная безобидная шутка для начинающего Linux админа:

# chmod -x chmod

К сожалению, сейчас решение очень легко находится через поиск. А вот когда-то давно это могло стать хорошим испытанием на сообразительность. Выходов из сложившейся ситуации много. Вот несколько примеров:

1️⃣ Используем утилиту setfacl. По умолчанию её может не быть в системе, но не проблема установить.

# setfacl -m u::rwx,g::rx,o::x /usr/bin/chmod

2️⃣ Можно запустить утилиту chmod, передав её явно динамическому компоновщику. В контексте данной заметки считайте компоновщик интерпретатором для программы chmod. В разных дистрибутивах он может иметь разное название и расположение. Пример для Debian 11:

# /usr/lib64/ld-linux-x86-64.so.2 /usr/bin/chmod +x /usr/bin/chmod

3️⃣ Можно скопировать права с любого исполняемого файла и записать содержимое утилиты chmod в этот файл. Получается рабочая копия chmod.

Создаём пустой файл с правами утилиты ls.

# cp --attributes-only /usr/bin/ls ./new_chmod

Копируем содержимое утилиты chmod в созданный файл:

# cat /usr/bin/chmod > ./new_chmod

Можно использовать:

# ./new_chmod +x /usr/bin/chmod

4️⃣ Почти то же самое что и предыдущий вариант только проще:

# install -m 755 /usr/bin/chmod ./new_chmod

или так:

# rsync --chmod=ugo+x /usr/bin/chmod ./new_chmod

5️⃣ Если умеете программировать на какой-то языке, то можно с его помощью вернуть бит исполнения. Пример с python:

python -c "import os;os.chmod('/usr/bin/chmod', 0755)"

Если знаете ещё какие-то интересные и необычные решения данной проблемы, делитесь в комментариях.

#terminal #linux #юмор

=========================================

#bash #terminal #find [https://t.me/srv_admin/1818](https://t.me/srv_admin/1818)

Давно не было заметок по полезным консольным командам под bash. В комментариях к заметке о find меня попросили поделиться своими шпаргалками для этой утилиты. Собрал наиболее универсальные и часто используемые конструкции.

Вывести только имена файлов. Поиск файлов пойдёт рекурсивно от той директории, где будет запущена команда:

# find | awk -F '/' '{print $NF;}'

Переместить найденные по маске файлы из одной директории в другую:

# find /mnt/backup/*site.ru* -type f -exec mv {} /web/sites/ \;

Найти все файлы по маске и сжать:

# find /data/1c-bases-backup -type f -name 1Cv8.1CD -exec gzip '{}' \;

Переименовать все найденные файлы:

# find /backup/sql -type f -name "*.sql.gz" -exec mv {} {}.old \;

Подробный список файлов размером больше 100М с помощью ls:

# find /data -type f -size +100M -exec ls -lh '{}' \;

Поиск файлов по содержимому (header.php):

# find /web/site.ru -type f -exec grep -i -H "header.php" {} \;

Посчитать количество найденных файлов:

# find /home/user -type f | wc -l

Найти файлы в определённом временном интервале:

# find /mnt/zz_archive -type f -newermt '2022-01-01 00:01' ! -newermt '2022-01-31 23:59'

Потом их можно сжать, переместить и т.д, как было показано в предыдущих примерах.

Искать без учёта регистра:

# find /data -type f -iname FILE_NAME

Поиск файлов, которые менялись сколько то дней назад и более:

# find /data -type f -mtime +30

или в течении последних 5 дней, но не позже:

# find /data -type f -mtime -5

или в определённом промежутке в минутах (10-20 минут назад):

# find /data -type f -mmin -20 -mmin +10

Cортировка по дате изменения:

# find /data -type f -printf '%TY-%Tm-%Td %TT %p\n' | sort -r

и обратная сортировка:

# find /data -type f -printf '%TY-%Tm-%Td %TT %p\n' | sort

Захватил наиболее типовые ситуации, с которыми чаще всего приходится сталкиваться в консоли или скриптах автоматизации.

#bash #terminal #find

==========================================

[https://losst.ru/kak-ochistit-korzinu-v-linux](https://losst.ru/kak-ochistit-korzinu-v-linux)

`sudo rm -Rf ~/.local/share/Trash`

sudo rm -rf /mnt/Z/.Trash*

[/mnt/Z/.Trash-0](file:///mnt/Z/.Trash-0)

`sudo rm -rf` [/mnt/Z/.Trash](file:///mnt/Z/.Trash-0)*

## Что делать если корзина не очищается

Случается и такое, случается потому что либо система не поддерживает кодировку имени файла, и в принципе не может с ним работать либо у вас не прав доступа к файлу. Но не важно почему, важно как решить. Откройте терминал комбинацией клавиш **Ctrl+Alt+T** и наберите команду:

`sudo rm -rf ~/.Trash/*`

Иногда корзина находиться в папке ~/.local/share:

`sudo rm -Rf ~/.local/share/Trash`

Вообще говоря корзина может находится где угодно, это зависит от настроек системы, найти папку с корзиной можно командой:

`find ~/ -name Trash`

Затем подставьте полученный результат в rm, только будьте очень осторожны, чтобы не удалить важные файлы, которые могут там быть.

[https://krayny.ru/linux/zametki/224-kak-ochistit-korzinu-v-ubuntu-s-pomoshchyu-terminala-konsoli.html](https://krayny.ru/linux/zametki/224-kak-ochistit-korzinu-v-ubuntu-s-pomoshchyu-terminala-konsoli.html)

Для каждого пользователя "Корзина" находится в каталоге

    .local/share/Trash

находящемся в домашней директории пользователя, который удалял файлы.

То есть находится по адресу:

    /home/Имя_Пользователя/.local/share/Trash

или под текущим пользователем:

    ~/.local/share/Trash

в каталоге "Корзины" есть два каталога:

    files — здесь хранятся непосредственно те файлы, которые можно увидеть в «Корзине»; удаление их из этого каталога приведет к удалению из файловой системы;

    info — местоположение вспомогательных файлов, в которых хранятся дополнительные сведения об удаленных объектах (полные пути, по которым располагались файлы в ФС до их удаления; даты момента их перемещения в корзину).

Кроме того, если вы удаляли что-то из под root пользователя.

То его корзина хранится здесь:

    /root/.local/share/Trash

Зайти в неё нельзя с помощью: sudo cd /root/.local/share/Trash Нужно зайти под root пользователем: sudo su Вводим пароль (авторизуемся), после чего уже можно зайти: cd /root/.local/share/Trash Кроме того не забываем выйти из root, после нужных манипуляций: exit Если Вы ничего не удаляли под root, то у Вас не будет данной папки "Корзины" root пользователя.

Приступаем к удалению из консоли.

Итак, в этом ничего нет сложного, просто очищаем рекурсивно все файлы в каталоге корзины:

Делается это следующим образом (очистим корзину текущего пользователя): rm -rf ~/.local/share/Trash/info/* ~/.local/share/Trash/files/* Команда rm -rf "опасная", поэтому проверяйте внимательно пути для удаления, чтобы нечаянно весь домашний каталог.

Аналогично удаляются корзины и других пользователей.

Вот и всё.

=======================================

[https://t.me/srv_admin/1831](https://t.me/srv_admin/1831)

Поднимал на днях тему просмотра логов в Linux. В комментариях неоднократно получил рекомендацию на утилиту lnav. Попробовал её и оценил. Классный функционал. Расскажу подробнее.

lnav есть в базовых репах Debian и RHEL. В других дистрибутивах не проверял. Ставится просто:

# apt install lnav

# dnf install lnav

Lnav понимает ряд наиболее популярных форматов логов, таких как access логи веб сервера, syslog, dpkg, strace и некоторые другие. Она их автоматически парсит, подсвечивает, позволяет быстро делать какие-то выборки. Например, посмотреть все ошибки в syslog, показать по ним статистику, вывести информацию по какой-то службе и т.д.

Основное, что очень понравилось в Lnav - возможность открыть сразу несколько логов и увидеть их наложение на одном экране. Это очень удобно в некоторых ситуациях, когда надо что-то расследовать. Нигде раньше не встречал подобного функционала. Когда нужно было сопоставить логи, открывал их либо в соседних вкладках на одном экране, либо как-то ещё. С Lnav просто делаем вот так и смотрим оба лога:

# lnav /var/log/auth.log /var/log/syslog

Если утилита распознала формат, то выстроит строки обоих логов в порядке времени событий. На картинке ниже пример.

Помимо прочего Lnav умеет сазу открывать архивные логи, отображать содержимое в режиме реального времени, применять сложные фильтры для отображения нужных строк.

Осталось хорошее впечатление классической консольной программы в Linux с полезным и уникальным функционалом. Рекомендую 👍

================================================

[https://t.me/srv_admin/1834](https://t.me/srv_admin/1834)

Познакомился по рекомендации с полезным сервисом, который позволяет записывать действия в консоли Linux или Windows (powershell), публиковать их в общий доступ для просмотра в браузере или создавать на их основе gif ролики.

Всё это можно сделать с помощью Terminalizer:

[https://github.com/faressoft/terminalizer](https://github.com/faressoft/terminalizer)

Open Source программа, написанная на JavaScript. Установить можно с помощью npm:

# apt install npm

# npm install -g terminalizer

Если будете запускать под root, как это делаю обычно я, то добавьте пару ключей:

# npm install -g terminalizer --unsafe-perm=true --allow-root

Для того, чтобы записать свою работу в консоли, достаточно запустить terminalizer и в качестве параметра указать имя файла, в который будет записана последовательность действий и вывод экрана:

# terminalizer record demo-rolik

Утилита напишет, что для завершения записи надо нажать CTRL+D, но у меня это не срабатывало при подключении по ssh. Так что выходил, просто набирая в консоли:

# exit

После окончания записи вам предложат зарегистрироваться на сайте [https://terminalizer.com](https://terminalizer.com) и выложить запись в общий доступ. Можете отказаться, если вам этого не нужно. Если же согласитесь, то получите ссылку вида [https://terminalizer.com/view/eaf819495681,](https://terminalizer.com/view/eaf819495681,) которую можно посмотреть в браузере.

Если не хотите загружать на сайт, то можете просмотреть запись в терминале:

# terminalizer play demo-rolik

Или сгенерировать на его основе гифку:

# terminalizer render demo-rolik

Для того, чтобы гифка в итоге получилась, нужна куча зависимостей, потому что используется electron и gtk. Как минимум нужно будет поставить:

# apt install libgtk-3-0 libgtk-3-dev

# apt install libxss1

# apt install xscreensaver

Насколько я понял, если у вас ноут с графикой, то всё это там будет. Я тестировал на чистом Ubuntu Server с голой консолью. Под root тоже не заведётся без танцев с бубном, так как electron по дефолту не хочет под ним работать. Нужен обычный юзер.

Из недостатков заметил один баг в готовых роликах. Немного обрезается верхняя часть шрифтов. Возможно это исправляется настройками отображения, которые можно очень гибко настраивать. Там и цвет, и шрифт, и его размер и многое другое. Я не разбирался. В репе есть описание всех возможностей.

С помощью terminalizer можно просить о помощи, записывая свои действия и вывод. Либо сохранять какие-то свои наработки, инструкции, примеры. Так как все записи хранятся в обычных текстовых файлах формата yml, положить всё это можно в git репозиторий.

#terminal

=============================================

[https://t.me/srv_admin/1840](https://t.me/srv_admin/1840)

Нашёл отличный сервис, который выдаёт информацию об ip адресе. При этом работает совершенно бесплатно и без регистрации. Не надо никаких учёток создавать, токены получать. Сервис - [https://ip-api.com](https://ip-api.com)

Простой пример проверки IP адреса с получением информации в формате json:

# curl [http://ip-api.com/json/1.1.1.1](http://ip-api.com/json/1.1.1.1)

Чтобы получился красивый вывод, можно использовать jq ([https://t.me/srv_admin/643](https://t.me/srv_admin/643)):

# curl [http://ip-api.com/json/1.1.1.1](http://ip-api.com/json/1.1.1.1) | jq

Все возможные форматы запросов и ответов можно посмотреть в документации ([https://ip-api.com/docs](https://ip-api.com/docs)). Можно, к примеру, явно указать, какие поля ответа вы хотите получить, чтобы потом у себя не приходилось самому обрабатывать ответ и убирать лишние поля.

Индийский товарищ по имени Rajkumar Dusad написал небольшой софт (IP-Tracer ([https://github.com/rajkumardusad/IP-Tracer](https://github.com/rajkumardusad/IP-Tracer))) на php, который через этот сервис проверяет IP адреса в консоли, причём в том числе на смартфонах с использованием Termux. Не знаю, кому этот софт может понадобиться, но звездочек на гитхабе у него полно. Про ip-api.com я узнал как раз, когда наткнулся на эту утилиту. Решил посмотреть, откуда она информацию берёт.

Ограничение ip-api.com - не более 45 запросов в минуту. Кому надо больше - добро пожаловать на платные тарифы.

#сервис #бесплатно

=======================================================================

logrotate

[https://t.me/srv_admin/1860](https://t.me/srv_admin/1860)

ServerAdmin.ru, [28.04.2022 18:30]

При настройке любой службы в Linux, которая пишет логи, надо обязательно следить за их ротацией. Типовая ситуация, когда логи забивают всё свободное место на диске, и сервак встаёт колом. Ротировать логи можно встроенной утилитой Linux - logrotate.

Для логов веб сайтов полезно включать ротацию не по заданному расписанию, а по размеру лог файла. Иногда случаются набеги ботов, которые могут раздуть логи до огромных размеров за несколько минут. Дождаться суточной ротации можно и не успеть. В этом случае полезно использовать следующий параметр logrotate:

size = 100M

Обычно люди ставят его и ожидают, что теперь логи будут автоматически ротироваться при достижении ими размера в 100 мегабайт. Ага, сейчас. Ничего подобного не произойдёт. По умолчанию logrotate запускается раз в сутки, поэтому он при всём желании не сможет следить за размером файла и ротировать его чаще, чем раз в сутки. Обычно за его запуск отвечает скрипт в директории /etc/cron.daily/logrotate.

Для того, чтобы logrotate мог проверять размер лог файла хотя бы раз в час, скрипт запуска надо перенести в директорию /etc/cron.hourly. А для более частой проверки, добавить его напрямую в cron с нужным интервалом запуска. Например, раз в 5 минут.

Допустим вы всё это сделали, но логи всё равно не будут ротироваться при достижении заданного размера. Понять, в чем же теперь проблема, не так просто. При запуске logrotate вы не увидите никаких ошибок. Он просто ничего не будет делать. Понять, в чём проблема, можно только при запуске в режиме отладки. Там вы увидите ошибку, если в этот день ротация уже была хотя бы раз.

destination /var/log/nginx/access.log.20220426.gz already exists, skipping rotation

Смысл тут в том, что logrotate сегодня уже произвел ротацию и создал архив лога с определенным именем и второй раз такой же файл он сделать не может. А маска имени файла при создании настроена в формате %Y%m%d. За эту маску отвечает параметр в /etc/logrotate.conf:

dateext

Самый простой вариант - это просто закомментировать этот параметр, тогда все архивы логов будут иметь следующую маску в файлах:

access.log.1.gz

access.log.2.gz

access.log.3.gz

Если же вам хочется сохранить исходный формат лога для всех файлов, а для тех, что ротируются по размеру, настроить другую маску имени, используйте дополнительный параметр:

dateformat -%Y-%m-%d_%H-%s

Формат имени архивного лога будет access.log.2022-04-26_15-1566819154.gz. Имена больше не будут дублироваться и logrotate сможет корректно запускать ротацию при достижении указанного размера файла.

Таким образом, чтобы настроить ротацию лог файла по достижении определенного размера, вам нужно:

1️⃣ Запускать через cron logrotate с достаточно высокой периодичностью, например раз в час или чаще.

2️⃣ Настроить маску файла для архива лога, чтобы она была уникальной в каждый момент запуска logrotate.

#logrotate #nginx #webserver

=============================================

ServerAdmin.ru, [27.04.2022 09:11]

Иногда возникает задача быстро удалить все таблицы в базе данных mysql, не удаляя саму базу данных. Доступ к базе через консоль. В общем случае удалить конкретную таблицу в базе db можно следующей командой:

> use db;

> drop table00 table01, table02;

Если таблиц немного, то можно поступить и так. Но если их много, то нужен какой-то другой способ. Можно изобрести или поискать какой-то готовый велосипед на bash. Я предлагаю вам свой 😁

Берём mysqldump и делаем дамп только структуры, добавляя информацию об удалении таблиц перед их созданием:

# mysqldump --add-drop-table --no-data db

Теперь получить консольные команды на удаление всех таблиц базы данных проще простого. Грепаем получившийся дамп:

# mysqldump --add-drop-table --no-data db | grep ^DROP

То есть выводим все строки, которые начинаются с DROP. Это как раз то, что нам нужно.

Далее можно либо взять только нужные строки с определёнными таблицами для удаления, либо сразу весь вывод отправить в консоль mysql и удалить все таблицы, оставив саму базу данных:

# mysqldump --add-drop-table --no-data db | grep ^DROP | mysql db

Не забудьте добавить авторизацию, если у вас она не настроена каким-то другим способом:

# mysqldump -uuser -ppassword --add-drop-table --no-data db \

| grep ^DROP | mysql -uuser -ppassword db

Таким простым способом, без скриптов, можно прямо в консоли сервера удалить все таблицы из базы данных mysql, не удаляя саму базу.

❓Может возникнуть вопрос, а почему не удалить всё же базу и не создать заново. Причин может быть несколько:

1️⃣ У вас нет прав на создание и удаление баз данных (наиболее частый случай).

2️⃣ Не помните точно параметры базы данных, не хочется вспоминать, искать, как создать новую базу данных с теми же параметрами, что стоят у текущей (мой случай).

Если у вас есть какое-то свое простое решение по удалению таблиц из базы, делитесь в комментариях.

#terminal #mysql

ServerAdmin.ru, [28.04.2022 18:30]

При настройке любой службы в Linux, которая пишет логи, надо обязательно следить за их ротацией. Типовая ситуация, когда логи забивают всё свободное место на диске, и сервак встаёт колом. Ротировать логи можно встроенной утилитой Linux - logrotate.

Для логов веб сайтов полезно включать ротацию не по заданному расписанию, а по размеру лог файла. Иногда случаются набеги ботов, которые могут раздуть логи до огромных размеров за несколько минут. Дождаться суточной ротации можно и не успеть. В этом случае полезно использовать следующий параметр logrotate:

size = 100M

Обычно люди ставят его и ожидают, что теперь логи будут автоматически ротироваться при достижении ими размера в 100 мегабайт. Ага, сейчас. Ничего подобного не произойдёт. По умолчанию logrotate запускается раз в сутки, поэтому он при всём желании не сможет следить за размером файла и ротировать его чаще, чем раз в сутки. Обычно за его запуск отвечает скрипт в директории /etc/cron.daily/logrotate.

Для того, чтобы logrotate мог проверять размер лог файла хотя бы раз в час, скрипт запуска надо перенести в директорию /etc/cron.hourly. А для более частой проверки, добавить его напрямую в cron с нужным интервалом запуска. Например, раз в 5 минут.

Допустим вы всё это сделали, но логи всё равно не будут ротироваться при достижении заданного размера. Понять, в чем же теперь проблема, не так просто. При запуске logrotate вы не увидите никаких ошибок. Он просто ничего не будет делать. Понять, в чём проблема, можно только при запуске в режиме отладки. Там вы увидите ошибку, если в этот день ротация уже была хотя бы раз.

destination /var/log/nginx/access.log.20220426.gz already exists, skipping rotation

Смысл тут в том, что logrotate сегодня уже произвел ротацию и создал архив лога с определенным именем и второй раз такой же файл он сделать не может. А маска имени файла при создании настроена в формате %Y%m%d. За эту маску отвечает параметр в /etc/logrotate.conf:

dateext

Самый простой вариант - это просто закомментировать этот параметр, тогда все архивы логов будут иметь следующую маску в файлах:

access.log.1.gz

access.log.2.gz

access.log.3.gz

Если же вам хочется сохранить исходный формат лога для всех файлов, а для тех, что ротируются по размеру, настроить другую маску имени, используйте дополнительный параметр:

dateformat -%Y-%m-%d_%H-%s

Формат имени архивного лога будет access.log.2022-04-26_15-1566819154.gz. Имена больше не будут дублироваться и logrotate сможет корректно запускать ротацию при достижении указанного размера файла.

Таким образом, чтобы настроить ротацию лог файла по достижении определенного размера, вам нужно:

1️⃣ Запускать через cron logrotate с достаточно высокой периодичностью, например раз в час или чаще.

2️⃣ Настроить маску файла для архива лога, чтобы она была уникальной в каждый момент запуска logrotate.

#logrotate #nginx #webserver

=============================================

[https://t.me/srv_admin/1898](https://t.me/srv_admin/1898)

Существует простая и удобная консольная утилита для работы с историей команд - HSTR (HiSToRy). В свежих версиях Debian, Ubuntu, RHEL (epel) она присутствует в базовых репозиториях.

Установка:

# apt install hstr

# dnf install hstr

[https://github.com/dvorka/hstr/blob/master/INSTALLATION.md#ubuntu](https://github.com/dvorka/hstr/blob/master/INSTALLATION.md#ubuntu)

## Ubuntu

HSTR is [included in Ubuntu 21.10](https://packages.ubuntu.com/impish/utils/hstr) and [newer](https://wiki.ubuntu.com/Releases) releases:

`sudo apt install hstr`

Install HSTR on **Ubuntu 21.04 and older** using one-liner:

sudo add-apt-repository ppa:ultradvorka/ppa && sudo apt-get update && sudo apt-get install hstr && hstr --show-configuration >> ~/.bashrc && . ~/.bashrc

... or step by step:

sudo add-apt-repository ppa:ultradvorka/ppa

sudo apt-get update

sudo apt-get install hstr

HSTR является заменой привычного функционала по Ctrl-r. Если просто запустить в консоли hstr (или алиас hh) без параметров, то увидите список всех команд из history, выстроенные по частоте их использования. Из этого списка их легко выбрать и запустить. По умолчанию будет активна строка поиска, где можно начать набор искомых команд. Поиск осуществляется по совпадению подстроки, регулярному выражению и ключевому слову

Утилита умеет удалять строки из истории, добавлять в избранное команды, ранжировать команды по их длине. Ключей и возможностей нет так много, долго разбираться не придётся. Все их можно посмотреть через man или встроенную справку:

# hh -h

HSTR маленькая и простая утилита. Написана на C. Присутствует в репозиториях, так что можно смело ставить и пользоваться. Хороший продукт.

Исходники - [https://github.com/dvorka/hstr](https://github.com/dvorka/hstr)

Инструкция по настройке:

[https://github.com/dvorka/hstr/blob/master/CONFIGURATION.md](https://github.com/dvorka/hstr/blob/master/CONFIGURATION.md)

#terminal #bash

=======================================================

PS

[https://t.me/srv_admin/1957](https://t.me/srv_admin/1957)

Одна из наиболее часто используемых команд консоли Linux, которую я набираю - ps (processes status). Это небольшая утилита для просмотра информации о запущенных процессах. У неё огромное количество ключей для представления информации. Если её запустить без них, то она покажет только список процессов данного терминала. Их может вообще не быть, кроме самой оболочки, в которой она запущена.

Сразу покажу команду, которую я использую чаще всего:

# ps ax

Выводит все процессы без привязки к пользователю и терминалу. Этот вывод чаще всего приходится грепать, чтобы посмотреть информацию по конкретному процессу. Например, поменял конфигурацию php-fpm на запуск определённого количества процессов, перезапустил демон и проверил, что процессов столько, сколько надо:

# ps ax | grep php-fpm

Можно сразу же пересчитать их количество для какого-то конкретного пула, если меняли только его настройки:

# ps ax | grep php-fpm | grep www | wc -l

Подозреваю, что тут можно и с одним грепом как-то обойтись, но я всегда делаю так. Либо можно использовать такой вариант:

# ps -F -C php-fpm

Но опять же, лично я привык использовать grep от полного списка. Вспоминать ключи не надо.

Если добавить ключ u, то можно посмотреть инфу об использовании ресурсов системы каждым процессом:

# ps axu

Лично я так редко делаю, привык смотреть эту инфу через htop. Почти всегда его ставлю, если сам настраиваю сервера и активно использую.

Полезно добавить к выводу ps ключ --forest, чтобы получить иерархический список процессов. Если просматриваете его весь, то будет нагляднее для анализа:

# ps ax --forest

Если вывод ps слишком длинный, вместо того, чтобы потом скролить терминал, можно добавлять less

# ps ax --forest | less

Less полезно использовать, чтобы увидеть полные строки процессов с параметрами, так как при таком просмотре выполняется перенос строк. Чтобы строки не обрезались, надо дважды добавить ключ -w

# ps ax -w -w

Теперь немного инфы из закладок. Не запоминал эти конструкции.

Вывод списка процессов с отображением информации о потребляемых CPU и MEM с сортировкой по первому:

# ps -e -o pcpu,pmem,args --sort -pcpu

Иногда бывает полезно этот список сверху обрезать:

# ps -e -o pcpu,pmem,args --sort -pcpu | head -10

Список самых тяжёлых процессов по памяти с выводом информации о pid и user этого процесса. Ну и заодно столбцы с mem и cpu переносим вправо, чтобы удобнее смотреть было:

# ps -eo pid,user,cmd,%mem,%cpu --sort=-%mem | head -10

Если к командам выше добавить watch, то эту информацию можно смотреть в режиме реального времени:

# watch -n 1 'ps -eo pid,user,cmd,%mem,%cpu --sort=-%mem | head -10'

Ну и в завершении ПАПА-скрипт, который соберёт информацию обо всех процессах, в том числе с повторяющимися именами, просуммирует их потребление и выведет общий список:

# ps axo rss,comm,pid | awk '{ proc_list[$2] += $1; } END \

{ for (proc in proc_list) { printf("%d\t%s\n", proc_list[proc],proc); }}' \

| sort -n | tail -n 10 | sort -rn \

| awk '{$1/=1024;printf "%.0fMB\t",$1}{print $2}'

#bash #terminal

===========================================

![file://e:/Temp/app/.SBYMW1/1.png](file://e:/Temp/app/.SBYMW1/1.png)

=======================================================

[https://t.me/srv_admin/1979](https://t.me/srv_admin/1979)

Если у вас есть желание поменьше зависеть от облачных сервисов и побольше информации хранить у себя, то могу посоветовать хороший self-hosted сервис для хранения закладок - linkding. Это бесплатное Open Source решение с хорошим рейтингом и отзывами.

Linkding написан на Python, запускается в докере. Все свои данные хранит в одной указанной директории. Основные возможности:

- тэги для организации закладок

- поиск по названиям или тэгам

- автоматическое создание снепшотов закладок на основе archive.org

- импорт и экспорт закладок в HTML формат

- дополнения в Chrome и Firefox для работы с закладками

- REST API для интеграций

- используется SQLite для хранения данных

Запустить и попробовать проще простого:

# docker run --name linkding -p 9090:9090 \

-v ~/linkding/data:/etc/linkding/data \

-d sissbruecker/linkding:latest

Либо воспользоваться Demo.

Я попробовал, но мне особо не требуется такая штука, так как закладок очень мало. Давно заметил, что даже если что-то сохраню, потом всё равно не возвращаюсь. Мне достаточно 20-30 закладок на панели браузера для наиболее часто посещаемых ресурсов.

А саму тенденцию отказа от публичных сервисов я поддерживаю, если есть нормальная альтернатива. Например, все заметки или пароли храню только у себя. В браузерах пароли давно не сохраняю. Заметки храню в Joplin.

Исходники - [https://github.com/sissbruecker/linkding](https://github.com/sissbruecker/linkding)

Demo - [https://demo.linkding.link/](https://demo.linkding.link/)

===============================================================

[https://losst.ru/42-komandy-linux-kotorye-vy-dolzhny-znat](https://losst.ru/42-komandy-linux-kotorye-vy-dolzhny-znat)

# 42 КОМАНДЫ LINUX КОТОРЫЕ ВЫ ДОЛЖНЫ ЗНАТЬ

### Команды

 Обновлено: 

###  3 ноября, 2020

 

### 35

 

### admin

 

### bash

### , 

### команды

Во всех операционных системах, в том числе и в Linux, термин 'команда' означает либо утилиту командной строки, либо определённую возможность, встроенную в командную оболочку системы. Тем не менее, для самих пользователей это различие не имеет особого значения. В конце концов, и те и другие команды терминала Linux вызываются одинаково. Вы вводите слово в вашем эмуляторе терминала и получаете результат выполнения команды.

Я уже писал о командах терминала Linux, но тогда затронул лишь несколько самых интересных, самых полезных команд, рассчитывая на то, что пользователь уже достаточно знаком с возможностями терминала. Но нужно сделать ещё одну статью, рассчитанную на новичков, тех, кто только делает свои первые шаги в освоении Linux.

И вот она. Её цель - собрать основные простые и сложные команды Linux, которые должен знать каждый пользователь, чтобы наиболее эффективно управлять своей системой. Для удобности запоминания опций команд я в скобках добавил слова, от которых они произошли - так намного проще, на себе проверено.

Это не значит, что я перечислю все команды, все перечислены [тут](https://losst.ru/komandy-terminala-linux) - я постараюсь охватить всё самое полезное, то, что может пригодиться в повседневной жизни. Чтобы было удобнее читать, разделим этот список на категории команд по назначению. Большинство рассмотренных здесь утилит не требуют дополнительной установки, они будут предустановлены в любом дистрибутиве Linux, а если не будут, то их несложно найти в официальных репозиториях.

Содержание статьи:

• [Команды Linux для управления файлами](https://losst.ru/42-komandy-linux-kotorye-vy-dolzhny-znat#%D0%9A%D0%BE%D0%BC%D0%B0%D0%BD%D0%B4%D1%8B_Linux_%D0%B4%D0%BB%D1%8F_%D1%83%D0%BF%D1%80%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F_%D1%84%D0%B0%D0%B9%D0%BB%D0%B0%D0%BC%D0%B8)

• [Linux команды консоли для работы с текстом](https://losst.ru/42-komandy-linux-kotorye-vy-dolzhny-znat#Linux_%D0%BA%D0%BE%D0%BC%D0%B0%D0%BD%D0%B4%D1%8B_%D0%BA%D0%BE%D0%BD%D1%81%D0%BE%D0%BB%D0%B8_%D0%B4%D0%BB%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%8B_%D1%81_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BE%D0%BC)

• [Команды Linux для управления процессами](https://losst.ru/42-komandy-linux-kotorye-vy-dolzhny-znat#%D0%9A%D0%BE%D0%BC%D0%B0%D0%BD%D0%B4%D1%8B_Linux_%D0%B4%D0%BB%D1%8F_%D1%83%D0%BF%D1%80%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%B0%D0%BC%D0%B8)

• [Команды Linux окружения пользователя](https://losst.ru/42-komandy-linux-kotorye-vy-dolzhny-znat#%D0%9A%D0%BE%D0%BC%D0%B0%D0%BD%D0%B4%D1%8B_Linux_%D0%BE%D0%BA%D1%80%D1%83%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8F)

• [Команды Linux для управления пользователями](https://losst.ru/42-komandy-linux-kotorye-vy-dolzhny-znat#%D0%9A%D0%BE%D0%BC%D0%B0%D0%BD%D0%B4%D1%8B_Linux_%D0%B4%D0%BB%D1%8F_%D1%83%D0%BF%D1%80%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8F%D0%BC%D0%B8)

• [Linux команды для просмотра документации](https://losst.ru/42-komandy-linux-kotorye-vy-dolzhny-znat#Linux_%D0%BA%D0%BE%D0%BC%D0%B0%D0%BD%D0%B4%D1%8B_%D0%B4%D0%BB%D1%8F_%D0%BF%D1%80%D0%BE%D1%81%D0%BC%D0%BE%D1%82%D1%80%D0%B0_%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%86%D0%B8%D0%B8)

• [Команды Linux для управления сетью](https://losst.ru/42-komandy-linux-kotorye-vy-dolzhny-znat#%D0%9A%D0%BE%D0%BC%D0%B0%D0%BD%D0%B4%D1%8B_Linux_%D0%B4%D0%BB%D1%8F_%D1%83%D0%BF%D1%80%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F_%D1%81%D0%B5%D1%82%D1%8C%D1%8E)

• [Выводы](https://losst.ru/42-komandy-linux-kotorye-vy-dolzhny-znat#%D0%92%D1%8B%D0%B2%D0%BE%D0%B4%D1%8B)

## КОМАНДЫ LINUX ДЛЯ УПРАВЛЕНИЯ ФАЙЛАМИ

#### 1. LS

Утилита для просмотра содержимого каталогов. По умолчанию показывает текущий каталог. Если в параметрах указать путь, то она перечислит содержимое конечного каталога. Полезные опции -l (**L**ist) и -a (**A**ll). Первая форматирует вывод в виде списка с более подробной информацией, а вторая включает показ скрытых файлов. Подробнее [здесь](https://losst.ru/komanda-ls-linux).

#### 2. CAT

Печатает содержимое файла, переданного в параметре, в стандартный вывод. Если передать несколько файлов, команда склеит их. Также можно перенаправить вывод в ещё один файл с помощью символа '>'. Если нужно вывести только определенное количество строк, используйте опцию -n (**N**umber). Подробнее [тут](https://losst.ru/komanda-cat-linux).

#### 3. CD

Позволяет перейти из текущего каталога в указанный. Если запустить без параметров - возвращает в домашний каталог. Вызов с двумя точками возвращает на уровень вверх относительно текущего каталога. Вызов с тире (cd -) возвращает к предыдущему каталогу. Более детально [здесь](https://losst.ru/komanda-cd-linux).

#### 4. PWD

Печатает на экран текущий каталог. Это может быть полезно, если ваша командная строка Linux не выводит такую информацию. Эта команда будет востребована в Bash программировании, где для получения ссылки на каталог выполняется скрипт. Более подробно в отдельной [статье](https://losst.ru/komanda-pwd-linux).

#### 5. MKDIR

Создание новых каталогов. Наиболее удобная опция -p (**P**arents), позволяет создать всю структуру подкаталогов одной командой, даже если они ещё не существуют. Подробнее о том как создать папку читайте в [отдельной](https://losst.ru/kak-sozdat-papku-ubuntu) статье.

#### 6. FILE

Команда [file](https://losst.ru/komanda-file-v-linux) показывает тип файла. В Linux файлы не обязаны всегда иметь расширения для того, чтобы с ними работать. Поэтому пользователю иногда трудно определить, что за файл перед ним. Эта маленькая утилита решает проблему.

#### 7. CP

[Копирование файлов и каталогов](https://losst.ru/kopirovanie-fajlov-v-linux). Она не копирует каталоги по умолчанию рекурсивно (то есть все поддиректории и все файлы в поддиректориях), поэтому не забудьте добавить опцию -r (**R**ecursive) или -a (**A**rchive). Последняя включает режим сохранения атрибутов, владельца и временного штампа в дополнение к рекурсивному копированию.

#### 8. MV

Перемещение или переименование файлов и каталогов. Примечательно, что в Linux это одна и та же операция. Переименование - это перемещение файла в ту же папку с другим именем. Подробнее - [здесь](https://losst.ru/kak-pereimenovat-fajl-linux).

#### 9. RM

Удаляет файлы и папки. Очень полезная команда Linux: с её помощью вы можете убрать весь беспорядок. Если нужно рекурсивное удаление, используйте опцию -r. Однако будьте осторожны: конечно, для того чтобы повредить систему вам нужно будет серьёзно постараться, однако можно удалить собственные важные файлы. Rm удаляет файлы не в корзину, из которой потом всё можно будет восстановить, а полностью стирает. Действия оператора **rm** необратимы. Поверьте, ваши оправдания в духе "rm съела мою курсовую" никому не будут интересны. Подробнее в [этой](https://losst.ru/kak-udalit-fajl-cherez-terminal-linux) статье.

####  10. LN

Создает [жёсткие или символические ссылки](https://losst.ru/simvolicheskie-i-zhestkie-ssylki-linux) на файлы. Символические или программные ссылки - это что-то похожее на ярлыки в Windows. Они предоставляют удобный способ доступа к определённому файлу. Символические ссылки указывают на файл, но не имеют никаких метаданных. Жёсткие ссылки, в отличие от символических, указывают на физический адрес области диска, где хранятся данные файла.

#### 11. CHMOD

[Изменяет права](https://losst.ru/komanda-chmod-linux) доступа к файлу. Это чтение, запись и выполнение. Каждый пользователь может изменять права для своих файлов.

#### 12. CHOWN

[Изменяет владельца](https://losst.ru/komanda-chown-linux) файла. Только суперпользователь может изменять владельцев. Для рекурсивного изменения используйте опцию -R.

#### 13. FIND

[Поиск](https://losst.ru/komanda-find-v-linux) в файловой системе, файлах и папках. Это очень гибкая и мощная команда Linux не только из-за своих способностей ищейки, но и благодаря возможности выполнять произвольные команды для найденных файлов.

#### 14. LOCATE

В отличие от find, команда locate ведёт поиск в базе данных updatedb для шаблонов имён файлов. Эта база данных содержит снимок файловой системы, что позволяет искать очень быстро. Но этот поиск ненадёжен, потому что вы не можете быть уверены, что ничего не изменилось с момента последнего снимка. Подробнее - [тут](https://losst.ru/komanda-locate-v-linux).

#### 15. DU

Показывает размер файла или каталога. Самые полезные опций: -h (**H**uman), которая преобразует размеры файлов в легко читаемый формат, -s (**S**ummarize), которая выводит минимум данных, и -d (**D**epth), устанавливающая глубину рекурсии по каталогам.

#### 16. DF

[Анализатор дискового пространства](https://losst.ru/komanda-df-linux). По умолчанию вывод достаточно подробный: перечислены все файловые системы, их размер, количество использованного и свободного пространства. Для удобства есть опция -h, делающая размеры легко читаемыми.

#### 17. DD

Как сказано в официальном руководстве, это команда терминала для копирования и преобразования файлов. Не очень понятное описание, но это всё, что делает [dd](https://losst.ru/komanda-dd-linux). Вы передаёте ей файл-источник, пункт назначения и пару дополнительных опций. Затем она делает копию одного файла в другой. Вы можете задать точный размер данных, которые нужно записать или скопировать. Работает утилита со всеми устройствами. Например, если вы хотите перезаписать жёсткий диск нулями из /dev/zero, можете сделать это. Также она часто используется для создания LiveUSB или гибридных ISO образов.

#### 18 MOUNT / UMOUNT

Это команды консоли Linux для подключения и отключения файловых систем Linux. Можно подключать всё: от USB накопителей, до ISO образов. И только у суперпользователя есть права для этого.

## LINUX КОМАНДЫ КОНСОЛИ ДЛЯ РАБОТЫ С ТЕКСТОМ

#### 19. MORE / LESS

Это две простенькие команды терминала для просмотра длинных текстов, которые не вмещаются на одном экране. Представьте себе очень длинный вывод команды. Или вы вызвали cat для просмотра файла, и вашему эмулятору терминала потребовалось несколько секунд, чтобы прокрутить весь текст. Если ваш терминал не поддерживает прокрутки, вы можете сделать это с помощью [less](https://losst.ru/komanda-less-v-linux). Less новее, чем [more](https://losst.ru/komanda-more-v-linux) и поддерживает больше опций, поэтому использовать more нет причин.

#### 20. HEAD / TAIL

Ещё одна пара, но здесь у каждой команды своя область применения. Утилита [head](https://losst.ru/komanda-head-linux) выводит несколько первых строк из файла (голова), а [tail](https://losst.ru/komanda-tail-linux) выдает несколько последних строк (хвост). По умолчанию каждая утилита выводит десять строк. Но это можно изменить с помощью опции -n. Ещё один полезный параметр -f, это сокращение от **f**ollow (следовать). Утилита постоянно выводит изменения в файле на экран. Например, если вы хотите следить за лог файлом, вместо того, чтобы постоянно открывать и закрывать его, используйте команду tail -nf.

#### 21. GREP

[Grep](https://losst.ru/gerp-poisk-vnutri-fajlov-v-linux), как и другие инструменты Linux, делает одно действие, но делает его хорошо: она ищет текст по шаблону. По умолчанию она принимает стандартный ввод, но вы можете искать в файлах. Шаблон может быть строкой или регулярным выражением. Она может вывести как совпадающие, так и не совпадающие строки и их контекст. Каждый раз, когда вы выполняете команду, которая выдает очень много информации, не нужно анализировать всё вручную - пусть grep делает свою магию.

#### 22. SORT

[Сортировка строк текста](https://losst.ru/komanda-sort-v-linux) по различным критериям. Наиболее полезные опции: -n (**N**umeric), по числовому значению, и -r (**R**everse), которая переворачивает вывод. Это может быть полезно для сортировки вывода du. Например, если хотите отсортировать файлы по размеру, просто соедините эти команды.

#### 23. WC

Утилита командной строки Linux для подсчёта количества слов, строк, байт и символов. Подробнее [тут](https://losst.ru/komanda-wc-v-linux).

#### 24. DIFF

Показывает различия между двумя файлами в построчном сравнении. Причём выводятся только строки, в которых обнаружены отличия. Измененные строки отмечаются символом "с", удалнные - "d", а новые - "а". Подробнее - [здесь](https://losst.ru/sravnenie-fajlov-v-linux).

Кстати, я подготовил ещё одну подробную статью, в которой описан именно [просмотр содержимого текстового файла в Linux](https://losst.ru/kak-otkryt-tekstovyj-fajl-linux) c помощью терминала.

## КОМАНДЫ LINUX ДЛЯ УПРАВЛЕНИЯ ПРОЦЕССАМИ

#### 25. KILL / XKILL / PKILL / KILLALL

Служат для завершения процессов. Но они принимают различные параметры для идентификации процессов. Kill нужен PID процесса, xkill - достаточно кликнуть по окну, чтобы закрыть его, killall и pkill принимают имя процесса. Используйте ту, которая удобна в определенной ситуации.

#### 26. PS / PGREP

Как уже говорилось, чтобы уничтожить процесс, нужен его идентификатор. Один из способов получить его, это утилита ps, которая печатает информацию о запущенных процессах. По умолчанию вывод очень длинный, поэтому используйте опцию -e, чтобы увидеть информацию об определённом процессе. Это только снимок состояния на момент вызова, и информация не будет обновляться. Команда ps с ключом aux выводит полную информацию о процессах. Pgrep работает следующим образом: вы задаете имя процесса, а утилита показывает его идентификатор. Подробнее о команде [ps](https://losst.ru/komanda-ps-v-linux) описано тут.

#### 27. TOP / HTOP

Обе команды похожи, обе отображают процессы и могут быть использованы как консольные системные мониторы. Я рекомендую установить htop, если в вашем дистрибутиве он не поставляется по умолчанию, так как это улучшенная версия top. Вы сможете не только просматривать, но и контролировать процессы через его интерактивный интерфейс.

#### 28. TIME

Время выполнения процесса. Это секундомер для выполнения программы. Полезно, если вам интересно, насколько сильно ваша реализация алгоритма отстает от стандартной. Но, несмотря на такое название, она не сообщит вам текущее время, используйте для этого команду date.

## КОМАНДЫ LINUX ОКРУЖЕНИЯ ПОЛЬЗОВАТЕЛЯ

#### 29. SU / SUDO

Su и sudo - это два способа выполнить одну и ту же задачу: запустить программу от имени другого пользователя. В зависимости от вашего дистрибутива вы, наверное, используете одну или другую. Но работают обе. Разница в том, что su переключает вас на другого пользователя, а sudo только выполняет команду от его имени. Поэтому использование sudo будет наиболее безопасным вариантом работы. Я писал про [права суперпользователя](https://losst.ru/prava-superpolzovatelya-linux) в этой статье.

#### 30. DATE

В отличие от time, делает именно то, чего вы от неё и ожидаете: выводит дату и время в стандартный вывод. Его можно форматировать в зависимости от ваших потребностей: вывести год, месяц, день, установить 12-ти или 24-ти часовой формат, получить наносекунды или номер недели. Например, date +"%j %V", выведет день в году и номер недели в формате ISO.

#### 31. ALIAS

Команда создаёт синонимы для других команд Linux. То есть вы можете делать новые команды или группы команд, а также переименовывать существующие. Это очень удобно для сокращения длинных команд, которые вы часто используете, или создания более понятных имен для команд, которые вы используете нечасто и не можете запомнить. [Здесь](https://losst.ru/poleznye-alias-linux) собрано несколько полезных алиасов.

#### 32. UNAME

Выводит некую основную информацию о системе. Без параметров она не покажет ничего полезного, кроме строчки Linux, но, если задать параметр -a (**A**ll), можно получить [информацию о ядре](https://losst.ru/kak-uznat-versiyu-yadra-linux), имени хоста и узнать архитектуру процессора.

#### 33. UPTIME

Сообщает вам время работы системы. Не очень существенная информация, но может быть полезна для случайных вычислений или просто ради интереса, чтобы узнать, как давно был перезагружен сервер.

#### 34. SLEEP

Вам, наверное, интересно как же её можно использовать. Даже не учитывая Bash-скриптинг, у неё есть свои преимущества. Например, если вы хотите выключить компьютер через определенный промежуток времени или использовать в качестве импровизированной тревоги.

## КОМАНДЫ LINUX ДЛЯ УПРАВЛЕНИЯ ПОЛЬЗОВАТЕЛЯМИ

#### 35. USERADD / USERDEL / USERMOD

Эти команды консоли Linux позволяют вам добавлять, удалять и изменять учетные записи пользователей. Скорее всего, вы не будете использовать их очень часто. Особенно если это домашний компьютер, и вы являетесь единственным пользователем. Управлять пользователями можно и с помощью графического интерфейса, но лучше знать об этих командах на всякий случай.

#### 36. PASSWD

Эта команда позволяет изменить пароль учетной записи пользователя. Как суперпользователь вы можете сбросить пароли всех пользователей, даже несмотря на то, что не можете их увидеть. Хорошая практика безопасности - менять пароль почаще.

## LINUX КОМАНДЫ ДЛЯ ПРОСМОТРА ДОКУМЕНТАЦИИ

#### 37. MAN / WHATIS

Команда man открывает руководство по определённой команде. Для всех основных команд Linux есть man страницы. Whatis показывает, какие разделы руководств есть для данной команды.

#### 38. WHEREIS

Показывает полный путь к исполняемому файлу программы. Также может показать путь к исходникам, если они есть в системе.

## КОМАНДЫ LINUX ДЛЯ УПРАВЛЕНИЯ СЕТЬЮ

#### 39. IP

Если список команд Linux для управления сетью вам кажется слишком коротким, скорее всего вы не знакомы с [утилитой ip](https://losst.ru/nastrojka-seti-v-linux). В пакете net-tools содержится множество других утилит: ipconfig, netstat и прочие устаревшие, вроде iproute2. Всё это заменяет одна утилита - ip. Вы можете рассматривать её как швейцарский армейский нож для работы с сетью или как непонятную массу, но в любом случае за ней будущее. Просто смиритесь с этим.

#### 40. PING

[Ping](https://losst.ru/komanda-ping-v-linux) - это ICMP ECHO_REQUEST дейтаграммы, но на самом деле это неважно. Важно то, что утилита ping может быть очень полезным диагностическим инструментом. Она поможет быстро проверить, подключены ли вы к маршрутизатору или к интернету, и дает кое-какое представление о качестве этой связи.

#### 41. NETHOGS

Если у вас медленный интернет, то вам, наверное, было бы интересно знать, сколько трафика использует какая-либо программа в Linux или какая программа потребляет всю скорость. Теперь это можно сделать с помощью утилиты nethogs. Для того чтобы задать сетевой интерфейс используйте опцию -i.

#### 42. TRACEROUTE

Это усовершенствованная версия ping. Мы можем увидеть не только полный маршрут сетевых пакетов, но и доступность узла, а также время доставки этих пакетов на каждый из узлов. Подробнее - [тут](https://losst.ru/komanda-traceroute-linux).

## ВЫВОДЫ

Мы рассмотрели основные команды Linux, которые могут пригодиться вам при повседневном использовании системы. Если вы считаете, что есть другие команды, которые нужно добавить в этот список, напишите в комментариях!

##### Хранение ключей сторонних репозиториев в 22.04+

[https://forum.ubuntu.ru/index.php?topic=318119](https://forum.ubuntu.ru/index.php?topic=318119)

### В общем, добавление ключей в /etc/apt/trusted.gpg.d с помощью "apt-key add" считается небезопасным, начиная с Debian 11 и Ubuntu 22.04 настоятельно рекомендуется избегать и apt-key использовать лишь для удаления уже добавленных ключей. (Когда вопрос возник, посмотрел первый попавшийся PPA, ключ лёг в /etc/apt/trusted.gpg.d - реформаторы, однако...)

### Ключевое, видимо:

Цитировать

The problem is that any key you add to either of the above is completely and unconditionally trusted by apt. This means that when installing any package from any repo (including the official distro repos), apt will happily accept the package being signed by any of those trusted keys (whether the key belongs to the repository the package is coming from or not). This weakens the assurance provided by the package signing mechanism against malicous packages being injected into the official Ubuntu mirrors network.

What we want to do instead is configure apt to accept signatures from a third-party repository only on packages being installed from that repository — no cross-signing. Apt's default pinning rules give higher priority to official distro repos, which (in conjunction with proper key management) offers some protection against third-party repos replacing distro-provided packages.

### Т.е. если, например, пакеты Wine из репозитория Wine, подписанные ключом Wine, внезапно окажутся в официальном репозитории Ubuntu или Debian, где по идее должны лежать лишь пакеты, подписанные в Ubuntu или Debian, то они будут проигнорированы apt? Если да, это вообще реальная ситуация?

### Ну и о запрете замены любых пакетов из официального репозитория пакетами из стороннего речь ведь не идёт?

### Пара ссылок:

[https://askubuntu.com/questions/1286545/what-commands-exactly-should-replace-the-deprecated-apt-key](https://askubuntu.com/questions/1286545/what-commands-exactly-should-replace-the-deprecated-apt-key)

[https://www.linuxuprising.com/2021/01/apt-key-is-deprecated-how-to-add.html](https://www.linuxuprising.com/2021/01/apt-key-is-deprecated-how-to-add.html)